{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importa bibliotecas para trabalhar com o NLTK (Natural Language Toolkit)"
      ],
      "metadata": {
        "id": "RfmYSFDDheGa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VOXaHTpxurMw"
      },
      "outputs": [],
      "source": [
        "from nltk.util import pad_sequence\n",
        "from nltk.util import bigrams\n",
        "from nltk.util import ngrams\n",
        "from nltk.util import everygrams\n",
        "from nltk.lm import Laplace\n",
        "from nltk.lm import KneserNeyInterpolated\n",
        "from nltk.lm.preprocessing import pad_both_ends\n",
        "from nltk.lm.preprocessing import flatten\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "id": "9tBWE6JMQsrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b3da1c-580f-44cd-cb55-41f41399e49f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para gerar bigramas de um texto, primeiro é necessário transformar as palavras em tokens.\n",
        "\n",
        "Entretanto, o primeiro passo é separar as frases do texto. A função `sent_tokenize` utiliza um tokenizador de frases, que separa as frases em uma lista conforme a pontuação presente no texto.\n",
        "\n",
        "Com as frases separadas, é necessário separar as palavras do texto para que elas seja transformadas em tokens. Para isso, é utilizado o `word_tokenize` que separa as palavras no texto, conforme a ocorrência de espaços, virgulas, entre outros.\n",
        "\n",
        "Aqui, `tokenized_text` contém o texto tokeniado por frases encontradas no texto"
      ],
      "metadata": {
        "id": "Mmm5PLSwgS8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'The quick brown fox jumps over the lazy dog. The five boxing wizards jump quickly.'\n",
        "sentences = sent_tokenize(text)\n",
        "print(sentences)\n",
        "print(word_tokenize(sentences[0]))\n",
        "tokenized_text = [list(map(str.lower, word_tokenize(sent)))\n",
        "                  for sent in sent_tokenize(text)]\n",
        "print(tokenized_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ms8ZCUPhvA9s",
        "outputId": "a0a0b3cf-0e26-4b8e-b1ff-cd0b53d55ebc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The quick brown fox jumps over the lazy dog.', 'The five boxing wizards jump quickly.']\n",
            "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
            "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'], ['the', 'five', 'boxing', 'wizards', 'jump', 'quickly', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `padded_everygram_pipeline` gera, a partir dos tokens, n-gramas conforme parâmetro e também uma lista com os tokens do texto arrajados conforme a sua disposição no texto.\n",
        "\n",
        "Observe que essa função já adiciona os símbolos terminadores de frase, entretanto o ponto final foi transformado em uma palavra por estar contido no texto.\n",
        "\n",
        "Para evitar de gerar esse tipo de token, a pontuação deve ser removida da lista de tokens"
      ],
      "metadata": {
        "id": "ZaVKU66lhmN2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = 2\n",
        "train_data, vocab = padded_everygram_pipeline(n, tokenized_text)\n",
        "# Filter for bigrams before printing\n",
        "print([ngram for ngram in list(flatten(train_data)) if len(ngram) == 2])\n",
        "print(list(vocab))"
      ],
      "metadata": {
        "id": "P8eqr5SswOXA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1be1a54-687f-411f-ddbe-ebd327e26c6e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('<s>', 'the'), ('the', 'quick'), ('quick', 'brown'), ('brown', 'fox'), ('fox', 'jumps'), ('jumps', 'over'), ('over', 'the'), ('the', 'lazy'), ('lazy', 'dog'), ('dog', '.'), ('.', '</s>'), ('<s>', 'the'), ('the', 'five'), ('five', 'boxing'), ('boxing', 'wizards'), ('wizards', 'jump'), ('jump', 'quickly'), ('quickly', '.'), ('.', '</s>')]\n",
            "['<s>', 'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.', '</s>', '<s>', 'the', 'five', 'boxing', 'wizards', 'jump', 'quickly', '.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui é removido da lista todas as palavras que sejam iguais a lista d pontuação da classe string.\n",
        "\n",
        "Então, a função `padded_everygram_pipeline` é processada novamente. Agora, os sinais de pontuação foram removidos."
      ],
      "metadata": {
        "id": "BjbYccjgiVJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove punctuation tokens\n",
        "filtered_word_tokens_from_sentences = [[word for word in sentence if word not in string.punctuation]\n",
        "                                         for sentence in tokenized_text]\n",
        "\n",
        "print(filtered_word_tokens_from_sentences)\n",
        "\n",
        "# Preprocess the tokenized text for 3-grams language modelling\n",
        "n = 2\n",
        "train_data, vocab = padded_everygram_pipeline(n, filtered_word_tokens_from_sentences)\n",
        "print(list(flatten(train_data)))\n",
        "print(list(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkjTnXtTgFDQ",
        "outputId": "1d1a409c-dfb2-4b55-e14e-d802b6cd99bc"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog'], ['the', 'five', 'boxing', 'wizards', 'jump', 'quickly']]\n",
            "[('<s>',), ('<s>', 'the'), ('the',), ('the', 'quick'), ('quick',), ('quick', 'brown'), ('brown',), ('brown', 'fox'), ('fox',), ('fox', 'jumps'), ('jumps',), ('jumps', 'over'), ('over',), ('over', 'the'), ('the',), ('the', 'lazy'), ('lazy',), ('lazy', 'dog'), ('dog',), ('dog', '</s>'), ('</s>',), ('<s>',), ('<s>', 'the'), ('the',), ('the', 'five'), ('five',), ('five', 'boxing'), ('boxing',), ('boxing', 'wizards'), ('wizards',), ('wizards', 'jump'), ('jump',), ('jump', 'quickly'), ('quickly',), ('quickly', '</s>'), ('</s>',)]\n",
            "['<s>', 'the', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '</s>', '<s>', 'the', 'five', 'boxing', 'wizards', 'jump', 'quickly', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "É criado o modelo do tipo KneserNeyInterpolated. Os dados de `train_data` e `vocab`são processador novamente pois as funções de print na célula anterior alteram o estado desses objetos"
      ],
      "metadata": {
        "id": "Xso0eiaxK6OI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = KneserNeyInterpolated(n)\n",
        "train_data, vocab = padded_everygram_pipeline(n, filtered_word_tokens_from_sentences)"
      ],
      "metadata": {
        "id": "N4LufJMewfX2"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "É realizado o treinamento do modelo. Após exibe-se as informações do vocabulário gerado."
      ],
      "metadata": {
        "id": "t8UmZ7Gmhq5f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_data, vocab)\n",
        "print(model.vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WtlmpQS_wm8_",
        "outputId": "db3cedd0-4f31-43eb-e2bb-47a8d18226ba"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Vocabulary with cutoff=1 unk_label='<UNK>' and 16 items>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apresenta a pontuação de cada *token* do vocabulário gerado"
      ],
      "metadata": {
        "id": "RZPFPlsrLb7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for word in model.vocab:\n",
        "  print(f\"Score for {word}: {model.score(word)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uI1LJiwiws9Z",
        "outputId": "4f8d7bee-b9a3-4647-9f79-18b00d5ed75e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Score for <s>: 0.0\n",
            "Score for the: 0.125\n",
            "Score for quick: 0.0625\n",
            "Score for brown: 0.0625\n",
            "Score for fox: 0.0625\n",
            "Score for jumps: 0.0625\n",
            "Score for over: 0.0625\n",
            "Score for lazy: 0.0625\n",
            "Score for dog: 0.0625\n",
            "Score for </s>: 0.125\n",
            "Score for five: 0.0625\n",
            "Score for boxing: 0.0625\n",
            "Score for wizards: 0.0625\n",
            "Score for jump: 0.0625\n",
            "Score for quickly: 0.0625\n",
            "Score for <UNK>: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(model.vocab.lookup('the quick brown fox lah .'.split()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G3mTFZzTw2tb",
        "outputId": "840ead64-9dbb-4286-93dc-98bb050986e7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('the', 'quick', 'brown', 'fox', '<UNK>', '<UNK>')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v7kuMuRzxCBc",
        "outputId": "5f0a3738-891c-45f3-854c-92e2e75960ff"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<NgramCounter with 2 ngram orders and 36 ngrams>\n"
          ]
        }
      ]
    }
  ]
}